# gtts-scripts

Скрипты для предварительной обработки текста книг для их прослушивания в text-to-speech движках

Возможно использовать совместно со скриптом обработки книг fb2: https://github.com/Balamoote/fb2-scripts</br>

Скрипты в основном предназначены для получения улучшенного звучания за счёт проставления ударений на движках TTS, которые понимают ударения.</br>

При желании можно использовать:

- с TTSLexx, находящимся тут: https://play.google.com/store/apps/details?id=sia.netttsengine.ttslexx</br>
- со словарем, находящимся тут: https://github.com/Balamoote/gtts-dic (устарело)</br>

Задача коррекции звучания на конкретном движке решается путем составления корректировочных словарей, которые на входе принимаю уже размеченный
ударениями текст, а на выходе выдают результат, понятный TTS-движку. Пример в директории slexx для TTSLexx.

При использовании дополнительно к автоматической ещё и ручной обработки омографов через дискретные скрипты, при желании, можно добиться 100% обработки всех
омографов в тексте.

Документация находится внутри папки tools/docs (устарела), а также в самих скриптах.

Могут быть полезны и для других движков после адаптации. Например, скрипт ёфикации (yofik.sh) может считаться полностью независимым, но он не ставит задачи
ёфикации омографов. Эту задачу выполняет скрипт momo.sh, а проставление ударений в именах собственных делает get-words.sh.

Стандартная последовательность обработки для получения ёфицированного текста с ударениями с именах и омографах (ключ -gg включает большинство опций):</br>
(опционально: ./fb2fix.sh -gc book.fb2 = делает почти то же, что и "генеральная уборка" в FictionBook Editor)</br>
./yofik.sh -gg book.fb2 = ёфикация, кроме омографов, которые при желании можно обработать вручную.</br>
./get-words.sh -gg book.fb2 = проставить ударения в известных именах и собрать неизвестные имена и слова для внесения в базы</br>
./momo.sh -gg book.fb2 = выполнить автообработку части омографов и при желании вручную обработать остатки.</br>

Альтернативно, можно сразу использовать пакет ruaccent, который находится тут:</br>
https://github.com/Den4ikAI/ruaccent . В этом случае будут проставлены ударения во всех словах теста.

./momo.sh -ruac book.fb2 = выполнить автообработку всех слов текста, включая омографы, и ёфикацию.</br>

Настройку работы ruaccent можно сделать в файле scripts/ruac.py</br>
В случае использования ruaccent будут сохранены уже имеющиеся ударения. Быстрая полная обработка, ценой некоторого понижения качества расстановки ударений в омографах,
если делать обработку только вручную.
Рекомендуется выполнить расстановку ударений в именах собственных до обработки ruaccent (./get-words.sh).

О времени работы. Зависит от мощности системы и обрабатываемой книги. Однако, нужно обратить внимание, что при первом запуске скрипта ./momo.sh создается база,
которая при повторных запусках сокращает время работа на 20-30 секунд. Для того, чтобы это работало необходим GNU AWK версии не ниже 5.2.1. Указанная база существует
в двух вариантах: для конкретной книги, куда попадают только обнаруженные в книге словарные словоформы, и полная словарная база, которая грузится только при запуске
утилиты ./testrule.sh. Это сокращает используемый объем памяти. Следует обратить внимание, что использование функции анализа spacy по-прежнему требует около 4 Гб
памяти, но только при первом запуске для каждой книги.</br>

В tools находится рабочий комплект для обработки книг.</br>

Для скрипта ./momo.sh есть возможность включить GNU Parallel и значительно увеличить скорость работы.
См. переменную do_parallel=1 в самом скрипте.

Скрипт scriptdb/./hclean.sh может быть вызван с ключами -spell_all, -spell_flat которые дадут списки слов для последующей генерации словарей проверки орфографии,
например для vim/neovim. Обратите внимание, что этот скрипт сразу устанавливает готовый словарь для vim -- измените при необходимости.

Словарные базы.
Скрипты работают на основе нескольких словарных баз, в зависимости от назначения скриптов. Основными источниками являются:

1. "Полная парадигма. Морфология. Частотный словарь. Совмещенный словарь. Автор М. Хаген. Полная парадигма. Морфология". http://speakrus.ru/dict2/index.htm#morph-paradigm
   является основой, исправляется и дополняется;
2. «Открытый корпус» (OpenCorpora) https://opencorpora.org/dict.php - является источником пополнения словарных баз;
3. Wiktionary https://ru.wiktionary.org/ - является источником пополнения словарных баз (см. https://kaikki.org/dictionary/rawdata.html);
4. YOL https://github.com/vgiv/yo - основа базы ёфикации, исправлена и дополнена.

Словарные базы разделяются на две независимые части. Первая часть обеспечивает морфологический анализ текста, она направлена на обработку омографов правилами.
Вторая часть состоит из списков слов с ударениями. Базы между собой не связаны и не синхронизированы.

В bases находятся различные словарные базы, потенциально имеющие некоторый технически и академический интерес. Практического смысла в них почти нет. Можете их
смело игнорировать.

Требования:</br>
bash, grep, GNU sed, gawk>=5.2.1, dos2unix, uniq, sort, md5sum, zgrep, zcat, md5sum, gzip, bc

Рекомендации:</br>
iconv, mc, vim/nvim, GNU parallel, ripgrep, ruaccent, (natasha), (spacy)
